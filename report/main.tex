\documentclass{article}


% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2022


% ready for submission
\usepackage{neurips_2022}


% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2022}


% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2022}


% to avoid loading the natbib package, add option nonatbib:
%    \usepackage[nonatbib]{neurips_2022}
\usepackage{amsmath}
\usepackage{makecell}
\usepackage{graphicx}
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{listings}
\usepackage{xcolor}         % colors

% define colors
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

% line style
\lstdefinestyle{mystyle}{
backgroundcolor=\color{backcolour},
commentstyle=\color{codegreen},
keywordstyle=\color{magenta},
numberstyle=\tiny\color{codegray},
stringstyle=\color{codepurple},
basicstyle=\footnotesize\ttfamily,
breakatwhitespace=false,
breaklines=true, captionpos=b,
keepspaces=true, numbers=left,
numbersep=5pt, showspaces=false,
showstringspaces=false,
showtabs=false, tabsize=2,
}
\lstset{style=mystyle}

\makeatletter
\renewcommand{\@noticestring}{}
\makeatother

\title{Statistic Machine Learning Project}



% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.


\author{%
  David S.~Hippocampus\thanks{Use footnote for providing further information
    about author (webpage, alternative address)---\emph{not} for acknowledging
    funding agencies.} \\
  Department of Computer Science\\
  Cranberry-Lemon University\\
  Pittsburgh, PA 15213 \\
  \texttt{hippo@cs.cranberry-lemon.edu} \\
  % examples of more authors
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \AND
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
}


\begin{document}


\maketitle


\begin{abstract}
  To fulfill the demand of public bike that more fossil based transportation cans be replaced by bike and contribute to alleviating climate change, the city of Washington D.C. has recorded the observations high bike demand along with temporal and meteorological features. With this data, this project study is dedicated to help the city to predict the necessity of increasing number of bikes at certain hours. To achieve this goal, methods including Logistic Regression, KNN, bagging and boosting are deployeds to predict the target label with given feature. 
\end{abstract}


\section{Study case and Data} 
To further understand and practice the knowledge we have obtained from lectures. A case of classification problem was given that we can apply different methods on the data and understand the charactoristics and behaviours of these methods.

\subsection{Case and data description}
To help the city of Washington, D.C. understand whether increasing the number of public bikes is neccessary at some certain hour, a machine learning model is expected to predict the public bike demand for given temporal and meteorological features. \\

A data set contains 1600 random obeservations is provided for the model training. The target variable is binary for "high" or "low" demand for increasing bikes' number. The description of the features are given in Table \ref{tab:feature_description}

\begin{table}[!ht]
  \caption{Labels and features in the data set \citep{smlproject2024}}
  \label{tab:feature_description}
  \centering
    \begin{tabular}{p{4cm} p{8cm}}
    \toprule
    \textbf{Feature Name} & \textbf{Description} \\

    midrule
    increase\_stock \newline (prediction label) &
    \textbf{low\_bike\_demand} – no need to increase the number of bikes \newline
    \textbf{high\_bike\_demand} – the number of bikes needs to be increased \\
    \
    midrule
    hour\_of\_day & Hour of the day (from 0 to 23) \\
    day\_of\_week & Day of the week (from 0 – Monday to 6 – Sunday) \\
    month & Month (from 0 – January to 12 – December) \\
    holiday & If it is a holiday or not (0 – no holiday, 1 – holiday) \\
    weekday & If it is a weekday or not (0 – weekend, 1 – weekday) \\
    summertime & If it is summertime or not (0 – no summertime, 1 – summertime) \\
    temp & Temperature in Celsius degrees \\
    dew & Dew point in Celsius degrees \\
    humidity & Relative humidity (percentage) \\
    precip & Precipitation in mm \\
    snow & Amount of snow in the last hour in mm \\
    snow\_depth & Accumulated amount of snow in mm \\
    windspeed & Wind speed in km/h \\
    cloudcover & Percentage of the city covered in clouds \\
    visibility & Distance in km at which objects or landmarks can be clearly seen and identified \\
    \bottomrule
  \end{tabular}
\end{table}


\subsection{Exploratory data analysis}
Expolratory data analysis has been conducted to gain the knowledge of relations among features in the dataset. Also, following questions in the project introduction are answered in this section. 

\begin{enumerate}
  \item\label{question:i} Which are the numerical features and which are the categorical features? 
  \item\label{question:ii} Is there any trend to need increase in the availability of
\end{enumerate}

Out of that the ways to treat categorical features are different from numerical features, the featuresa are sorted into two groupd, numerical and categorical. This sort of them can be identified according to Table \ref{tab:feature_description}. The two groups are shown in Table \ref{tab:cat_num_list}, which also answers Quesiton \ref{question:i}.

\begin{table}[!ht]
\caption{Categorical and numerical features.}
\label{tab:cat_num_list}
\centering
  \begin{tabular}{p{4cm} p{4cm}}
  \toprule
  \textbf{Categorical features} & \textbf{Numerical features} \\
  \midrule
  holiday        & hour\_of\_day \\
  weekday        & day\_of\_week \\
  summertime     & month \\
  snow           & temp \\
  increase\_stock & dew \\
                & humidity \\
                & precip \\
                & snow\_depth \\
                & windspeed \\
                & cloudcover \\
                & visibility \\
  \bottomrule
  \end{tabular}
\end{table}

For categorical features, first step done was to see the label balance. The result is shown in Figure \ref{fig:cate_dist}. One thing to be noted is that the feature "snow" has only one label. A flat feature will not have input to the model, thus it was excloded from training set. This will be also seen in the correlation analysis.
\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.95\linewidth]{figures/count_plot_category.png}
  \caption{Label counts for categorical features}
  \label{fig:cate_dist}
\end{figure}

Similarily, histgram plot was generated to visualize the distribution of numerical features (shown in Figure \ref{fig:num_dist}). 

\begin{figure}[!ht]
  \begin{small}
    \begin{center}
      \includegraphics[width=0.95\textwidth]{figures/num_dist.png}
    \end{center}
    \caption{histgrams of numerical features}
    \label{fig:num_dist}
  \end{small}
\end{figure}

To understand the correlation among features, mostly between targets and other features, correlation analysis has been done ploting corrolation maps, shown in Figure \ref{fig:correlation}

\begin{figure}[!ht]
  \begin{small}
    \begin{center}
      \includegraphics[width=0.8\textwidth]{figures/corr_map.png}
    \end{center}
    \caption{Corrolation among features}
    \label{fig:correlation}
  \end{small}
\end{figure}

Droping out the smaller correlated features ($correlation \geq 0.1$), the left ones are: "temp", "humidity", "hour\_of\_day", "summertime", "dew", "weekday", and "visibility". To more intuitively see if any features can help seperate the target label. Figure \ref{fig:box_and_dist} was ploted. 

\begin{figure}[!ht]
  \begin{small}
    \begin{center}
      \includegraphics[width=0.95\textwidth]{figures/box_and_hist_features.png}

    \end{center}
    \caption{Boxs and Histgrams for features with different targets laebls}
    \label{fig:box_and_dist}
  \end{small}
\end{figure}

Finally, with all analysis and figures above, the Question \ref{question:ii} can be answered. \\ 
It is seen that the label "1" ("high\_bike\_demand") is concerntrated around daytime, growth starts from early morning, drops till late evening after reaching its peak at 15:00 to 16:00. Weekday has more "high\_bike\_demand" than weekends. \\ 
Temperature also has impact on bike demand, more bike are needed when temperture is in a comfortable region, 20 ~ 30 degC in data. This can also interprets the trend in the summertime, temperature is higher in summer, similarily for dew point.

\section{Methodology}
\subsection{Machine learning models}
\subsubsection{Boosting}
Boosting is an emsenble method which is built on the idea that even a week model can capture some patterns between target variables and given features. Starting from a base model, optmizing it based on the returned error can produce a new model which would become the base for next model. By ensembling the predictions from these models, the intention of boosting is to reduce bias\citep{Lindholm2022sml}.\\

In this study, three maintream boosting algorithm were deployed, \textbf{AdaBoost}\citep{Lindholm2022sml}, \textbf{GradientBoost}\citep{Lindholm2022sml}, and \textbf{CatBoost}\citep{prokhorenkova2018catboost}. The methods can expressed as following equations.

\begin{equation}
  \text{AdaBoost:\space \space}
  \hat{y}^{(B)}_{\text{boost}}(\mathbf{x})
  = \operatorname{sign}\!\left(
      \sum_{b=1}^{B} \alpha^{(b)} \hat{y}^{(b)}(\mathbf{x})
    \right)
  \label{eq:adaboost}
\end{equation}


\begin{equation}
  \text{GradientBoost:\space \space}
  f^{(B)}(\mathbf{x}) 
  = \sum_{b=1}^{B} \alpha^{(b)} f^{(b)}(\mathbf{x}),
  \label{eq:gradiantboost}
\end{equation}

\begin{equation}
  \text{CatBoost:\space \space} 
  f^{(B)}(\mathbf{x})
  = \sum_{b=1}^{B} \eta^{(b)} \, T^{(b)}(\mathbf{x})
  \label{eq:catboost}
\end{equation}




\subsection{Validation}
K-fold method with 5 subset was used for cross-validation to the deployed models.
Considering that label are imbalanced in the target variable, accuracy would not be a good choice for perfomance measurement. Precision, recall, and F1-score are used. 




\section{Results}
\subsection{Boosting}
Three boosting models were apply in this study, AdaBoostingClassifier and GradientBoostingClassifier from \textit{Scikit-learn},and CatBoostClassifier. Their perfomance is shown in Table \ref{tab:models_performance}


\begin{table}[!ht]
  \centering
  \caption{Boosting models performance}
  \label{tab:models_performance}
  \begin{tabular}{
    l
    cc
    cc
    cc
    c
  }
    \toprule

    \textbf{Model} &
    \multicolumn{2}{c}{\textbf{Precision}} &
    \multicolumn{2}{c}{\textbf{Recall}} &
    \multicolumn{2}{c}{\textbf{F1 Score}} &
    \textbf{Train Time (s)} \\

    \cmidrule(lr){2-3}
    \cmidrule(lr){4-5}
    \cmidrule(lr){6-7}

    & \textbf{1} & \textbf{0} & \textbf{1} & \textbf{0} & \textbf{1} & \textbf{0} & \\

    \midrule
    AdaBoostClassifier          & 0.6427 & 0.9161 & 0.6298 & 0.9184 & 0.6334 & 0.9170 & 0.0035 \\
    GradientBoostingClassifier & 0.7729 & 0.9238 & 0.6555 & 0.9549 & 0.7084 & 0.9391 & 0.0890 \\
    CatBoostClassifier         & 0.7828 & 0.9317 & 0.6932 & 0.9549 & 0.7337 & 0.9431 & 0.5812 \\
    \bottomrule
    
  \end{tabular}
\end{table}


According to the perfomance, CatBoostClassifier was chosen to the model to be Optimized on Hyperparameters, where \textit{GridSearch} was used. The result is shown in Table \ref{tab:cat_performance}.

\begin{table}[!ht]
  \centering
    \caption{Performance of optimized CatBoostClassifier}
    \label{tab:cat_performance}
  \begin{tabular}{ccccc}
    \toprule
    \textbf{Class} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-score} & \textbf{Support} \\
    
    \midrule
    0 & 0.92 & 0.91 & 0.91 & 270 \\
    1 & 0.54 & 0.58 & 0.56 & 50 \\

    \bottomrule
  \end{tabular}
\end{table}



\section{Discussion}

\section{Conclusion}



% \citep{breiman2001randomforest}   % (Breiman, 2001)
% \citet{hastie2009elements}        % Hastie et al. (2009)



\bibliographystyle{unsrtnat}
\bibliography{references}
\appendix


\section{Appendix}


Optionally include extra information (complete proofs, additional experiments and plots) in the appendix.
This section will often be part of the supplemental material.




\end{document}